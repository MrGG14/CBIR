{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52d26d11",
   "metadata": {},
   "source": [
    "# CNN + SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0e6e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "\n",
    "from keras.applications import VGG16\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04ada66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_similar(n, counts, reverse):\n",
    "    sorted_counts = sorted(counts.items(), key=lambda x:x[1], reverse=reverse)[:n] #Ordeno y me quedo con los 5 más parecidos\n",
    "    sorted_indexes = [idx[0] for idx in sorted_counts]\n",
    "    return sorted_indexes\n",
    "\n",
    "def display_n_similar(sorted_indexes, n):\n",
    "    if n <= 0:\n",
    "        print(\"El valor de n debe ser mayor que 0.\")\n",
    "        return\n",
    "\n",
    "    if n > len(sorted_indexes):\n",
    "        print(f\"Solo hay {len(sorted_indexes)} imágenes en la lista. Mostrando todas.\")\n",
    "        n = len(sorted_indexes)\n",
    "    fig, axs = plt.subplots(1, n, figsize=(15,15))\n",
    "    for i in range(n):\n",
    "        n_carpeta = (sorted_indexes[i][0])\n",
    "        n_img = (sorted_indexes[i][1])\n",
    "        path = images_path[(n_carpeta, n_img)]\n",
    "        im = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(im)\n",
    "        axs[i].axis('off')\n",
    "        titulo = f'{n_carpeta}_{n_img}'\n",
    "        axs[i].set_title(titulo)\n",
    "        \n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def get_images_path(carpetas, n_imgs):\n",
    "    images_path = {}\n",
    "    for carpeta in carpetas:\n",
    "        for i in range(n_imgs):\n",
    "            images_path[(carpeta[-7:], str(i))] = f'./dataset/{carpeta}/{carpeta[-9:]}_{str(i)}.JPEG'\n",
    "    return images_path #Devuelve un diccionario en el que la clave es (carpeta, id), y los valores los paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d336fb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_imgs = 100\n",
    "carpetas = [\"autobus-n04487081\", \"clavos-n03804744\", \"coche-n02814533\", \"collarin-n03814639\", \"desatascador-n03970156\",\n",
    "         \"gatos-n02123394\", \"mono-n02480495\", \"puentes-n04532670\", \"silla-n04099969\", \"perro-n02099601\", \n",
    "            \"pato-n01855672\", \"pizza-n07873807\", \"mar-n09428293\", \"ipod-n03584254\", \"platano-n07753592\", \"mascara_gas-n03424325\", \n",
    "            \"pajarita-n02883205\", \"mosca-n02190166\", \"helado-n07615774\", \"canon-n02950826\"]\n",
    "len(carpetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66581373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = get_images_path(carpetas, n_imgs)\n",
    "len(images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dc9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists('CNN_SIFT.npy'):\n",
    "    cnn_sift = np.load('CNN_SIFT.npy')\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "    descriptors = np.load('SIFT_descriptors.npy')\n",
    "    caracteristics = np.load('CNN_matrix.npy')\n",
    "    # Crear un diccionario para mapear la combinación única de carpeta e índice a las características\n",
    "    caracteristics_dict = {}\n",
    "    for row in caracteristics:\n",
    "        folder, index, *features = row\n",
    "        caracteristics_dict[(folder, index)] = features\n",
    "\n",
    "    # Crear una lista para almacenar las filas combinadas\n",
    "    combined_data = []\n",
    "\n",
    "    # Especifica el tamaño de lote\n",
    "    batch_size = 100\n",
    "\n",
    "    # Divide 'descriptors' en lotes más pequeños y combina los lotes con 'caracteristics'\n",
    "    for i in range(0, len(descriptors), batch_size):\n",
    "        descriptors_batch = descriptors[i:i+batch_size]\n",
    "\n",
    "        # Combinar 'descriptors_batch' con 'caracteristics' y almacenar en 'combined_data'\n",
    "        for row in descriptors_batch:\n",
    "            folder, index, *sift_descriptors = row\n",
    "            if (folder, index) in caracteristics_dict:\n",
    "                caracteristic_features = caracteristics_dict[(folder, index)]\n",
    "                \n",
    "                \n",
    "                caracteristic_features = scaler.fit_transform(np.array(caracteristic_features).reshape(1, -1))\n",
    "                sift_descriptors = scaler.fit_transform(np.array(sift_descriptors).reshape(1, -1))                \n",
    "                \n",
    "                combined_row = [folder, index] + caracteristic_features.tolist() + sift_descriptors.tolist()\n",
    "                combined_data.append(combined_row)\n",
    "\n",
    "    # Convertir la lista de filas combinadas en un array de NumPy\n",
    "    cnn_sift = np.save('CNN_SIFT', combined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04123d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_sift.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed32ee01",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neighbors = 20\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "knn = NearestNeighbors(n_neighbors=n_neighbors, algorithm='auto', metric='euclidean')\n",
    "\n",
    "cnn_sift_train = cnn_sift[:, 2:] #Quitamos los dos primeros pertenecientes a indices de la imagen\n",
    "knn.fit(cnn_sift_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73cd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "model = Model(inputs=base_model.input, outputs=base_model.layers[-1].output)\n",
    "sift = cv2.SIFT_create()\n",
    "\n",
    "# new_image_path = list(images_path.values())[random.randrange(0, len(carpetas)*n_imgs - 1)]\n",
    "# new_img = cv2.cvtColor(cv2.imread(new_image_path), cv2.COLOR_BGR2RGB)\n",
    "new_img = cv2.cvtColor(cv2.imread('./dataset/test/coches-/n02814533_199.JPEG'), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "_ , descriptors = sift.detectAndCompute(new_img, mask=None)\n",
    "\n",
    "# Redimensionar la imagen al tamaño requerido por el modelo\n",
    "target_size = (224, 224)\n",
    "new_img_cnn = cv2.resize(new_img, target_size)\n",
    "# Agregar una dimensión\n",
    "new_img_cnn = np.expand_dims(new_img_cnn, axis=0)\n",
    "# Normalizar la imagen\n",
    "new_img_cnn = preprocess_input(new_img_cnn)\n",
    "\n",
    "# Extraer las características de la imagen\n",
    "caracteristics_img = model.predict(new_img_cnn)\n",
    "caracteristics_flat = caracteristics_img.reshape(1, -1)\n",
    "\n",
    "\n",
    "new_shape = (len(descriptors), 25088)\n",
    "expanded_array = np.repeat(caracteristics_flat, new_shape[0], axis=0)\n",
    "full_arr = np.hstack((expanded_array, descriptors))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4ae4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = {}\n",
    "tiempo_inicio = time.time()\n",
    "for cnn_descrp in full_arr:\n",
    "    cnn_descrp = cnn_descrp.reshape(1, -1)\n",
    "    _, indice = knn.kneighbors(cnn_descrp, n_neighbors=n_neighbors)\n",
    "    for idx in indice[0]:\n",
    "        carpeta = str(int(cnn_sift[idx,0]))\n",
    "        num_img = str(int(cnn_sift[idx,1]))\n",
    "        id = (carpeta, num_img)\n",
    "        if id in counts:\n",
    "            counts[id] += 1\n",
    "        else:\n",
    "            counts[id] = 1\n",
    "tiempo_fin = time.time()\n",
    "tiempo_transcurrido = tiempo_fin - tiempo_inicio\n",
    "print(f\"Tiempo de ejecucion: {tiempo_transcurrido} segundos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b764a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a30d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_img)\n",
    "idx_similar = get_n_similar(n_neighbors, counts, 1)\n",
    "display_n_similar(idx_similar, 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
